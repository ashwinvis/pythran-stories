{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy's Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting is a neat feature of Numpy (and other similar array-oriented languages like Matlab). It makes it possible to avoid explicit loops on arrays (they are particularly inefficient in Numpy), and improves the abstraction level of your code, which is a good thing if you share the same abstraction.\n",
    "\n",
    "For instance, the addition between two 1D array when one of them only holds a single element is well defined: the single element is repeated along the axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = np.arange(10), np.array([10])\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is very similar to the addition between an array and a scalar, *btw*.\n",
    "\n",
    "So to store all the possible multiplication between two 1D arrays, one can create a new axis and turn them into 2D arrays, then use this broadcasting facility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  4,  8],\n",
       "       [ 3,  6, 12, 24],\n",
       "       [ 7, 14, 28, 56],\n",
       "       [ 9, 18, 36, 72]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = np.array([1,2,4,8]), np.array([1, 3, 7, 9])\n",
    "a[np.newaxis, :] * b[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting and Pythran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pythran uses [expression templates](https://en.wikipedia.org/wiki/Expression_templates) to optimize array expression, and end up with something that is similar to [numexpr](https://github.com/pydata/numexpr) performance wise.\n",
    "\n",
    "It's relatively easy for Pythran's expression template to broadcast between array and scalars, or between two arrays that don't have the same dimension, as the information required to perform the broadcasting is part of the type, thus it's known at compile time.\n",
    "\n",
    "But the broadcasting described above only depends on the size, and Pythran generally does not have access to it at compile time. So a dynamic behavior is needed. Roughly speaking, instead of explicitly iterating over the expression template, iterators parametrized by a step are used. This step is equal to one for regular operands, and to zero for broadcast operands, which results in part of the operator always repeating itself.\n",
    "\n",
    "What's its cost? Let's benchmark :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy implementation\n",
    "\n",
    "The original code performs a reduction over a broadcast multiplication. When doing so Numpy creates a temporary 2D array, then computes the sum. Using ``None`` for indexing is similar to ``np.newaxis``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def broadcast_numpy(x, y):\n",
    "    return (x[:, None] * y[None, :]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythran Implementation\n",
    "\n",
    "The Pythran implementation is straight-forward: just add the right annotation.\n",
    "\n",
    "*Note: The pythran magic is not available as is in pythran 0.7.4 or lower*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext pythran.magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%pythran -O3\n",
    "#pythran export broadcast_pythran(float64[], float64[])\n",
    "def broadcast_pythran(x, y):\n",
    "    return (x[:, None] * y[None, :]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython Implementation\n",
    "\n",
    "The Cython implementation makes the looping explicit. We use all the tricks we know to get a fast version: ``@cython.boundscheck(False)``, ``@cython.wraparound(False)`` and a manual look at the output of ``cython -a``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython --compile-args=-O3\n",
    "\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def broadcast_cython(double[::1] x, double[::1] y):\n",
    "    cdef int n = len(x)\n",
    "    cdef int i, j\n",
    "    cdef double res = 0\n",
    "    for i in xrange(n):\n",
    "        for j in xrange(n):\n",
    "            res += x[i] * y[j]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba Implementation\n",
    "\n",
    "The Numba version is very similar to the Cython one, without the need of declaring the actual types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "@numba.jit\n",
    "def broadcast_numba(x, y):\n",
    "    n = len(x)\n",
    "    res = 0\n",
    "    for i in xrange(n):\n",
    "        for j in xrange(n):\n",
    "            res += x[i] * y[j]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check\n",
    "\n",
    "Just to be sure all versions yield the same value :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "functions = OrderedDict()\n",
    "functions['numpy'] = broadcast_numpy\n",
    "functions['cython'] = broadcast_cython\n",
    "functions['pythran'] = broadcast_pythran\n",
    "functions['numba'] = broadcast_numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 21.4640902072\n",
      "cython 21.4640902072\n",
      "pythran 21.4640902072\n",
      "numba 21.4640902072\n"
     ]
    }
   ],
   "source": [
    "x = np.random.random(10).astype('float64')\n",
    "y = np.random.random(10).astype('float64')\n",
    "for name, function in functions.items():\n",
    "    print name, function(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark\n",
    "\n",
    "The actual benchmark just runs each function through ``timeit`` for various array sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy  1000 loops, best of 3: 1.81 ms per loop\n",
      " cython  1000 loops, best of 3: 847 µs per loop\n",
      " pythran  1000 loops, best of 3: 846 µs per loop\n",
      " numba  1000 loops, best of 3: 847 µs per loop\n",
      " numpy  10 loops, best of 3: 80.8 ms per loop\n",
      " cython  10 loops, best of 3: 21.1 ms per loop\n",
      " pythran  10 loops, best of 3: 21.2 ms per loop\n",
      " numba  10 loops, best of 3: 21.2 ms per loop\n",
      " numpy  1 loop, best of 3: 248 ms per loop\n",
      " cython  10 loops, best of 3: 84.9 ms per loop\n",
      " pythran  10 loops, best of 3: 84.8 ms per loop\n",
      " numba  10 loops, best of 3: 84.8 ms per loop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "sizes = [1e3, 5e3, 1e4]\n",
    "import pandas\n",
    "scores = pandas.DataFrame(data=0, columns=functions.keys(), index=sizes)\n",
    "for size in sizes:\n",
    "    size = int(size)\n",
    "    for name, function in functions.items():\n",
    "        print name, \" \",\n",
    "        x = np.random.random(size).astype('float64')\n",
    "        y = np.random.random(size).astype('float64')\n",
    "        result = %timeit -o function(x, y)\n",
    "        scores.loc[size, name] = result.best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results (time in seconds, lower is better) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numpy</th>\n",
       "      <th>cython</th>\n",
       "      <th>pythran</th>\n",
       "      <th>numba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.000847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000.0</th>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.021222</td>\n",
       "      <td>0.021157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>0.248488</td>\n",
       "      <td>0.084851</td>\n",
       "      <td>0.084849</td>\n",
       "      <td>0.084834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            numpy    cython   pythran     numba\n",
       "1000.0   0.001809  0.000847  0.000846  0.000847\n",
       "5000.0   0.080827  0.021096  0.021222  0.021157\n",
       "10000.0  0.248488  0.084851  0.084849  0.084834"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Numpy time (lower is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_scores = scores.copy()\n",
    "for column in normalized_scores.columns:\n",
    "    normalized_scores[column] /= scores['numpy']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numpy</th>\n",
       "      <th>cython</th>\n",
       "      <th>pythran</th>\n",
       "      <th>numba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.468133</td>\n",
       "      <td>0.467495</td>\n",
       "      <td>0.468023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260999</td>\n",
       "      <td>0.262561</td>\n",
       "      <td>0.261762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.341468</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.341400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         numpy    cython   pythran     numba\n",
       "1000.0     1.0  0.468133  0.467495  0.468023\n",
       "5000.0     1.0  0.260999  0.262561  0.261762\n",
       "10000.0    1.0  0.341468  0.341463  0.341400"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Conclusion\n",
    "\n",
    "At first glance, Cython, Pythran and Numba all manage to get a decent speedup over the Numpy version. So what's the point?\n",
    "\n",
    "1. Cython requires extra annotations, and explicit loops;\n",
    "2. Numba only requires a decorator, but still explicit loops;\n",
    "3. Pythran still requires a type annotation, but it keeps the Numpy abstraction.\n",
    "\n",
    "That's Pythran Leitmotiv: keep the Numpy abstraction, but try hard to make it run faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round Two: Using the compiler\n",
    "\n",
    "GCC (and Clang, and…) provide two flags that can be useful in this situation: ``-Ofast`` and ``-march=native``. The former is generally equivalent to ``-O3`` with a few extra flags, most notably ``-ffast-math`` that disregards standard compliance with respect to floating point operation; In our case it makes it possible to reorder the operations to perform the final reduction using SIMD instructions. And with ``-march=native``, the code gets specialized for the host architecture. In the case of this post (and the machine used to run the tests), it means it can use the [AVX](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions) instruction set and its 256bits vector register than can store four double precision floating!\n",
    "\n",
    "In the Pythran case, vectorization is currently activated through the (somehow experimental) ``-DUSE_BOOST_SIMD`` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%pythran -O3 -march=native -DUSE_BOOST_SIMD\n",
    "#pythran export broadcast_pythran_simd(float64[], float64[])\n",
    "def broadcast_pythran_simd(x, y):\n",
    "    return (x[:, None] * y[None, :]).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython -c=-Ofast -c=-march=native\n",
    "\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "def broadcast_cython_simd(double[::1] x, double[::1] y):\n",
    "    cdef int n = len(x)\n",
    "    cdef int i, j\n",
    "    cdef double res = 0\n",
    "    for i in xrange(n):\n",
    "        for j in xrange(n):\n",
    "            res += x[i] * y[j]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then rerun the previous benchmark, with these two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy  100 loops, best of 3: 1.8 ms per loop\n",
      " cython+simd  1000 loops, best of 3: 203 µs per loop\n",
      " pythran+simd  1000 loops, best of 3: 232 µs per loop\n",
      " numpy  10 loops, best of 3: 81.4 ms per loop\n",
      " cython+simd  100 loops, best of 3: 5.42 ms per loop\n",
      " pythran+simd  100 loops, best of 3: 5.98 ms per loop\n",
      " numpy  1 loop, best of 3: 249 ms per loop\n",
      " cython+simd  10 loops, best of 3: 21.5 ms per loop\n",
      " pythran+simd  10 loops, best of 3: 23.6 ms per loop\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simd_functions = OrderedDict()\n",
    "simd_functions['numpy'] = broadcast_numpy\n",
    "simd_functions['cython+simd'] = broadcast_cython_simd\n",
    "simd_functions['pythran+simd'] = broadcast_pythran_simd\n",
    "simd_scores = pandas.DataFrame(data=0, columns=simd_functions.keys(), index=sizes)\n",
    "for size in sizes:\n",
    "    size = int(size)\n",
    "    for name, function in simd_functions.items():\n",
    "        print name, \" \",\n",
    "        x = np.random.random(size).astype('float64')\n",
    "        y = np.random.random(size).astype('float64')\n",
    "        result = %timeit -o function(x, y)\n",
    "        simd_scores.loc[size, name] = result.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numpy</th>\n",
       "      <th>cython+simd</th>\n",
       "      <th>pythran+simd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000.0</th>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000.0</th>\n",
       "      <td>0.081422</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.005984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000.0</th>\n",
       "      <td>0.249028</td>\n",
       "      <td>0.021458</td>\n",
       "      <td>0.023631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            numpy  cython+simd  pythran+simd\n",
       "1000.0   0.001797     0.000203      0.000232\n",
       "5000.0   0.081422     0.005419      0.005984\n",
       "10000.0  0.249028     0.021458      0.023631"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simd_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "What happens there is that the underlying compiler is capable, on our simple case, to vectorize the loops and takes advantage of the vector register to speedup the computation. Although there's still a small overhead, Pythran is almost on par with Cython, even when vectorization is enabled, which means that the abstraction is still valid, even for complex feature like Numpy's broadcasting.\n",
    "\n",
    "Under the hood though, the approach is totally different: Pythran vectorizes the expression template and generates calls to [boost.simd](https://github.com/NumScale/boost.simd), while Cython fully relies on GCC/clang auto-vectorizer, which proves to be a good approach until one meets a code compilers cannot vectorize!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cython ; cython.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.4.post1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pythran; pythran.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.25.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numba.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g++-5.real (Debian 5.3.1-19) 5.3.1 20160509\r\n",
      "Copyright (C) 2015 Free Software Foundation, Inc.\r\n",
      "This is free software; see the source for copying conditions.  There is NO\r\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!g++ --version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
