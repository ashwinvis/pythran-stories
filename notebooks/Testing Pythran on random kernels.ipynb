{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every now and then, I hang around on stackoverflow, longing for numerical kernels to pass through [pythran](https://pythran.readthedocs.io). Here is the result of my recent wanderings :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's import(ant)\n",
    "import pythran, numpy as np\n",
    "%load_ext pythran.magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From stackoverflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## euclidian distance\n",
    "\n",
    "from https://stackoverflow.com/questions/50658884/why-this-numba-code-is-6x-slower-than-numpy-code . This kernel is interesting because it uses ``np.newaxis``, ``np.sum``) along an axis, and a matrix against transposed matrix dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def euclidean_distance_square(x1, x2):\n",
    "    return -2*np.dot(x1, x2.T) + np.expand_dims(np.sum(np.square(x1), axis=1), axis=1) + np.sum(np.square(x2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pythran\n",
    "#pythran export pythran_euclidean_distance_square(float64[1,:], float64[:,:])\n",
    "import numpy as np\n",
    "def pythran_euclidean_distance_square(x1, x2):\n",
    "    return -2*np.dot(x1, x2.T) + np.sum(np.square(x1), axis=1)[:, np.newaxis] + np.sum(np.square(x2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x1 = np.random.random((1, 512))\n",
    "x2 = np.random.random((10000, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.1 ms ± 905 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "11.1 ms ± 76.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit euclidean_distance_square(x1, x2)\n",
    "%timeit pythran_euclidean_distance_square(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, at some point in history, pythran failed to match the ``np.dot(x1, x2.T)`` pattern, but it now calls the appropriate blas API (``cblas_zgemm``) with the correct arguments, without copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated centers\n",
    "\n",
    "from https://stackoverflow.com/questions/50931002/cython-numpy-array-manipulation-slower-than-python/50964759. This is a funny kernel because of its use of list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def updated_centers(point, start, center):\n",
    "    return np.array([__cluster_mean(point[start[c]:start[c + 1]], center[c]) for c in range(center.shape[0])])\n",
    "\n",
    "def __cluster_mean(point, center):\n",
    "    return (np.sum(point, axis=0) + center) / (point.shape[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pythran\n",
    "#pythran export pythran_updated_centers(float64 [:, :], intc[:] , float64 [:, :] )\n",
    "import numpy as np\n",
    "def pythran_updated_centers(point, start, center):\n",
    "    return np.array([__cluster_mean(point[start[c]:start[c + 1]], center[c]) for c in range(center.shape[0])])\n",
    "\n",
    "def __cluster_mean(point, center):\n",
    "    return (np.sum(point, axis=0) + center) / (point.shape[0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n, m = 100000, 5\n",
    "k = n//2\n",
    "point = np.random.rand(n, m)\n",
    "start = 2*np.arange(k+1, dtype=np.int32)\n",
    "center=np.random.rand(k, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 ms ± 18.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "11.9 ms ± 71.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit updated_centers(point, start, center)\n",
    "%timeit pythran_updated_centers(point, start, center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a cool speedup, but that's normal: there is an explicit loop + array indexing pattern, and that's not where numpy shines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process\n",
    "\n",
    "from https://stackoverflow.com/questions/46334298/kernel-function-in-gaussian-processes, a very high level kernel. The pythran version uses indexing through ``np.newaxis`` instead of the reshaping, and generates a specialized version for arguments where the last dimension is known to be one. There's two version of the pythran kernel, compiled with different flags to showcase the effect of vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def gp(a, b, gamma=0.1):\n",
    "    \"\"\" GP squared exponential kernel \"\"\"\n",
    "    sq_dist = np.sum(a**2, 1).reshape(-1, 1) + np.sum(b**2, 1) - 2*np.dot(a, b.T)\n",
    "    return np.exp(-0.5 * (1 / gamma) * sq_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pythran\n",
    "#pythran export pythran_gp_novect(float64[:,1], float64[:,1])\n",
    "import numpy as np\n",
    "def pythran_gp_novect(a, b, gamma=0.1):\n",
    "    \"\"\" GP squared exponential kernel \"\"\"\n",
    "    sq_dist = np.sum(a**2, 1)[np.newaxis] + np.sum(b**2, 1) - 2*np.dot(a, b.T)\n",
    "    return np.exp(-0.5 * (1 / gamma) * sq_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pythran -DUSE_BOOST_SIMD -march=native\n",
    "#pythran export pythran_gp_vect(float64[:,1], float64[:,1])\n",
    "import numpy as np\n",
    "def pythran_gp_vect(a, b, gamma=0.1):\n",
    "    \"\"\" GP squared exponential kernel \"\"\"\n",
    "    sq_dist = np.sum(a**2, 1)[np.newaxis] + np.sum(b**2, 1) - 2*np.dot(a, b.T)\n",
    "    return np.exp(-0.5 * (1 / gamma) * sq_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = 300\n",
    "X = np.linspace(-5, 5, n).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.51 ms ± 6.73 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "1.21 ms ± 6.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "348 µs ± 20.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit gp(X, X)\n",
    "%timeit pythran_gp_novect(X, X)\n",
    "%timeit pythran_gp_vect(X, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that much of a gain without vectorization enable, but still Pythran can rip a few extra performance out of a very high level kernel. Unleashing vectorization is plain awesome here :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing\n",
    "\n",
    "from https://stackoverflow.com/questions/45714178/python-improving-image-processing-with-numpy, that's the kind of kernel where an explicit seems a natural fit, and where pythran shines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(A, B, sum_arr): # Proposed approach\n",
    "    B_ext = np.concatenate((B[1:], B))\n",
    "    n = len(A)\n",
    "    for i in range(n-1,-1,-1):\n",
    "        A *= B_ext[i:i+n] #roll B with i-increment and multiply\n",
    "        A[n-1-i] += sum_arr #add sum to A at index\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pythran\n",
    "import numpy as np\n",
    "#pythran export pythran_image_processing(int64[], int64[], int64)\n",
    "def pythran_image_processing(A, B, sum_arr): # Proposed approach\n",
    "    B_ext = np.concatenate((B[1:], B))\n",
    "    n = len(A)\n",
    "    for i in range(n-1,-1,-1):\n",
    "        A *= B_ext[i:i+n] #roll B with i-increment and multiply\n",
    "        A[n-1-i] += sum_arr #add sum to A at index\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "A = np.random.randint(0,255,(N))\n",
    "B = np.random.randint(0,255,(N))\n",
    "A_copy = A.copy()\n",
    "sum_arr = int(np.sum(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 ms ± 2.09 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "51.7 ms ± 2.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit image_processing(A, B, sum_arr)\n",
    "%timeit pythran_image_processing(A_copy, B, sum_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorenz Attractor \n",
    "\n",
    "from https://gist.github.com/dean-shaff/d1d0cdabf79e225ab96918b73916289f. yet another kernel with loops, but sometimes that's the way the problem is naturally expressed. Note that Pythran does not support start arguments yet :-/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def rungekuttastep(h,y,fprime,*args):\n",
    "    k1 = h*fprime(y,*args)\n",
    "    k2 = h*fprime(y + 0.5*k1,*args)\n",
    "    k3 = h*fprime(y + 0.5*k2,*args)\n",
    "    k4 = h*fprime(y + k3,*args)\n",
    "    y_np1 = y + (1./6.)*k1 + (1./3.)*k2 + (1./3.)*k3 + (1./6.)*k4\n",
    "    return y_np1\n",
    "\n",
    "def fprime_lorenz_numpy(y,*args):\n",
    "    sigma, rho, beta = args\n",
    "    yprime = np.zeros(y.shape[0])\n",
    "    yprime[0] = sigma*(y[1] - y[0])\n",
    "    yprime[1] = y[0]*(rho - y[2]) - y[1]\n",
    "    yprime[2] = y[0]*y[1] - beta*y[2]\n",
    "    return yprime\n",
    "\n",
    "def attractor(n_iter, sigma, rho, beta):\n",
    "    y = np.arange(3)\n",
    "    for i in np.arange(n_iter):\n",
    "        y = rungekuttastep(0.001,y,fprime_lorenz_numpy,sigma, rho, beta)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pythran\n",
    "import numpy as np\n",
    "def rungekuttastep(h,y,fprime,sigma, rho, beta):\n",
    "    k1 = h*fprime(y,sigma, rho, beta)\n",
    "    k2 = h*fprime(y + 0.5*k1,sigma, rho, beta)\n",
    "    k3 = h*fprime(y + 0.5*k2,sigma, rho, beta)\n",
    "    k4 = h*fprime(y + k3,sigma, rho, beta)\n",
    "    y_np1 = y + (1./6.)*k1 + (1./3.)*k2 + (1./3.)*k3 + (1./6.)*k4\n",
    "    return y_np1\n",
    "\n",
    "def fprime_lorenz_numpy(y,sigma, rho, beta):\n",
    "    yprime = np.zeros(y.shape[0])\n",
    "    yprime[0] = sigma*(y[1] - y[0])\n",
    "    yprime[1] = y[0]*(rho - y[2]) - y[1]\n",
    "    yprime[2] = y[0]*y[1] - beta*y[2]\n",
    "    return yprime\n",
    "\n",
    "#pythran export pythran_attractor(int, float, float, float)\n",
    "def pythran_attractor(n_iter, sigma, rho, beta):\n",
    "    y = np.arange(3)\n",
    "    for i in np.arange(n_iter):\n",
    "        y = rungekuttastep(0.001,y,fprime_lorenz_numpy,sigma, rho, beta)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 ms ± 68.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "682 µs ± 8.62 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit attractor(1000, 10.,28.,8./3.)\n",
    "%timeit pythran_attractor(1000, 10.,28.,8./3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, that's a lot of non-vectorized operation, not the best fit for numpy but that's okay for pythran. There's a function passed as a parameter of another function, but pythran can cope with that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
